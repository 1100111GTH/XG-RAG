import os
import sys
# æŠŠçˆ¶è·¯å¾„æ·»åŠ åˆ°æ£€ç´¢ç›®æ ‡ä¸­
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.append(parent_dir)
######################################################
from config.config import ai_name, weight_size, project_name, project_name_1, default_challenge, concurrency_limit, config_path, vector_original_path, rsa_pub, init_system_prompt
from core.db import write_persist_var, read_persist_var, read_all_file_record_key
from packages.sources.text_only import api_guid
######################################################
import time
from typing import Any, List, Optional, Tuple, Dict
import shelve
from threading import Lock
from Crypto.PublicKey import RSA
from Crypto.Cipher import PKCS1_OAEP
import base64
import requests
import numpy as np
######################################################
from langserve import RemoteRunnable
######################################################
import gradio as gr


# Langchain debug
# set_debug(True)


# API æ¥å…¥
def encrypt_challenge(challenge: str) -> str:
    cipher = PKCS1_OAEP.new(RSA.import_key(open(rsa_pub, "rb").read()))
    encrypt = cipher.encrypt(challenge.encode())
    return base64.b64encode(encrypt).decode('utf-8')
password = encrypt_challenge(default_challenge)
better_query = RemoteRunnable(url="http://localhost:2031/better_query/", headers={"P": password})
upload_process = RemoteRunnable(url="http://localhost:2031/upload_process/", headers={"P": password})
test_upload_process = RemoteRunnable(url="http://localhost:2031/test_upload_process/", headers={"P": password})
test_read_all_file_record_key = RemoteRunnable(url="http://localhost:2031/test_read_all_file_record_key/", headers={"P": password})
del_file_process = RemoteRunnable(url="http://localhost:2031/del_file_process/", headers={"P": password})
test_del_file_process = RemoteRunnable(url="http://localhost:2031/test_del_file_process/", headers={"P": password})
test_del_all_file_process = RemoteRunnable(url="http://localhost:2031/test_del_all_file_process/", headers={"P": password})
retrieve = RemoteRunnable(url="http://localhost:2031/retrieve/", headers={"P": password})
audio_text = RemoteRunnable(url="http://localhost:2031/audio_text/", headers={"P": password})
audio_generator = RemoteRunnable(url="http://localhost:2031/audio_generator/", headers={"P": password})
infer = RemoteRunnable(url="http://localhost:2031/infer/", headers={"P": password})
simple_infer = RemoteRunnable(url="http://localhost:2031/simple_infer/", headers={"P": password})
plus_links = RemoteRunnable(url="http://localhost:2031/plus_links/", headers={"P": password})
session_analyze = RemoteRunnable(url="http://localhost:2031/session_analyze/", headers={"P": password})
clean_history = RemoteRunnable(url="http://localhost:2031/clean_history/", headers={"P": password})


# åˆå§‹åŒ–å˜é‡
######################################################
# å‘é‡æ•°æ®åº“é”
manually_lock = 0
lock = Lock()
lock_1 = Lock()
# æ˜¯å¦æ­£åœ¨ Streaming
streaming = {}
# å¯¹è¯æ¨¡å¼
chatmode = ["åŸºç¡€å¯¹è¯", "æ•°æ®åº“å¯¹è¯", "æ•°æ®åº“å¯¹è¯ï¼ˆ æ— é™åˆ¶ ï¼‰"]
# ç½‘é¡µæ ‡å¿—
sign_path = f"/{project_name_1}/packages/sources/sign.png"
# å­˜å‚¨å¯¹è¯
messages = {}


# å®šä¹‰åŠŸèƒ½å‡½æ•°
######################################################
# è·å– messages id åˆ—è¡¨
def get_ids():
    if not messages:
        m_ids = "æ— "
        return m_ids
    else:
        m_ids = list(messages.keys())
        return m_ids
# åˆ‡æ¢é…ç½®å¼•å‘çš„å¯¹è¯å†å²åˆ é™¤
def dected_del(id_input):

    if not id_input:
        return [], [], ""
    else:
        clean_history.invoke({"id": id_input})
        if id_input in messages:
            del messages[id_input]
        else:
            pass
        clean_history.invoke({"id": f"dbtest_{id_input}"})
        if f"dbtest_{id_input}" in messages:
            del messages[f"dbtest_{id_input}"]
        else:
            pass

    return [], [], ""
# æ¥å…¥ ChatGPT æç¤º
def chatgpt_info():
    gr.Info("å¦‚éœ€ ChatGPT æ¥å…¥ï¼Œè¯·ä¿®æ”¹ config.py è®¾ç½®æ–‡ä»¶")
# æ•°æ®åº“æµ‹è¯•
def test_db(id_input, db_test):

    if db_test == "å¼€å¯":
        gr.Warning("éŸ³é¢‘è¯¢é—®æš‚ä¸æ”¯æŒ Test æ•°æ®åº“")
        c2 = gr.update(value=[], visible=True)
    elif db_test == "å…³é—­":
        c2 = gr.update(value=[], visible=False)

    if not id_input:
        return [], c2, ""
    else:
        clean_history.invoke({"id": id_input})
        if id_input in messages:
            del messages[id_input]
        else:
            pass
        clean_history.invoke({"id": f"dbtest_{id_input}"})
        if f"dbtest_{id_input}" in messages:
            del messages[f"dbtest_{id_input}"]
        else:
            pass
        return [], c2, ""
# ä» API åŠ è½½é…ç½®
def load_from_api(id_input, chat_mode_choose, history_analyze, db_test, query, chatbot):
    if read_persist_var("chat_mode_choose") == chat_mode_choose:
        if read_persist_var("history_analyze") == history_analyze:
            if read_persist_var("db_test") == db_test:
                if read_persist_var("db_test") == "å¼€å¯":
                    c2 = gr.update(visible=True)
                elif read_persist_var("db_test") == "å…³é—­":
                    c2 = gr.update(visible=False)
                c = gr.update(value=read_persist_var("chat_mode_choose"))
                h = gr.update(value=read_persist_var("history_analyze"))
                q = gr.update(value=read_persist_var("query_enhance"))
                q_1 = gr.update(value=read_persist_var("query_enhance_1"))
                d = gr.update(value=read_persist_var("db_test"))
                return c, h, q, q_1, d, query, chatbot, c2
            else:
                if read_persist_var("db_test") == "å¼€å¯":
                    c2 = gr.update(value=[], visible=True)
                elif read_persist_var("db_test") == "å…³é—­":
                    c2 = gr.update(value=[], visible=False)
                c = gr.update(value=read_persist_var("chat_mode_choose"))
                h = gr.update(value=read_persist_var("history_analyze"))
                q = gr.update(value=read_persist_var("query_enhance"))
                q_1 = gr.update(value=read_persist_var("query_enhance_1"))
                d = gr.update(value=read_persist_var("db_test"))
                if not id_input:
                    return c, h, q, q_1, d, "", [], c2
                else:
                    clean_history.invoke({"id": id_input})
                    if id_input in messages:
                        del messages[id_input]
                    else:
                        pass
                    clean_history.invoke({"id": f"dbtest_{id_input}"})
                    if f"dbtest_{id_input}" in messages:
                        del messages[f"dbtest_{id_input}"]
                    else:
                        pass
                    return c, h, q, q_1, d, "", [], c2
        else:
            if read_persist_var("db_test") == "å¼€å¯":
                c2 = gr.update(value=[], visible=True)
            elif read_persist_var("db_test") == "å…³é—­":
                c2 = gr.update(value=[], visible=False)
            c = gr.update(value=read_persist_var("chat_mode_choose"))
            h = gr.update(value=read_persist_var("history_analyze"))
            q = gr.update(value=read_persist_var("query_enhance"))
            q_1 = gr.update(value=read_persist_var("query_enhance_1"))
            d = gr.update(value=read_persist_var("db_test"))
            if not id_input:
                return c, h, q, q_1, d, "", [], c2
            else:
                clean_history.invoke({"id": id_input})
                if id_input in messages:
                    del messages[id_input]
                else:
                    pass
                clean_history.invoke({"id": f"dbtest_{id_input}"})
                if f"dbtest_{id_input}" in messages:
                    del messages[f"dbtest_{id_input}"]
                else:
                    pass
                return c, h, q, q_1, d, "", [], c2
    else:
        if read_persist_var("db_test") == "å¼€å¯":
            c2 = gr.update(value=[], visible=True)
        elif read_persist_var("db_test") == "å…³é—­":
            c2 = gr.update(value=[], visible=False)
        c = gr.update(value=read_persist_var("chat_mode_choose"))
        h = gr.update(value=read_persist_var("history_analyze"))
        q = gr.update(value=read_persist_var("query_enhance"))
        q_1 = gr.update(value=read_persist_var("query_enhance_1"))
        d = gr.update(value=read_persist_var("db_test"))
        if not id_input:
            return c, h, q, q_1, d, "", [], c2
        else:
            clean_history.invoke({"id": id_input})
            if id_input in messages:
                del messages[id_input]
            else:
                pass
            clean_history.invoke({"id": f"dbtest_{id_input}"})
            if f"dbtest_{id_input}" in messages:
                del messages[f"dbtest_{id_input}"]
            else:
                pass
            return c, h, q, q_1, d, "", [], c2
def load_from_api_1():
    s = gr.update(value=read_persist_var("system_prompt"))
    c = gr.update(value=read_persist_var("chat_mode_choose"))
    h = gr.update(value=read_persist_var("history_analyze"))
    q = gr.update(value=read_persist_var("query_enhance"))
    q_1 = gr.update(value=read_persist_var("query_enhance_1"))
    d = gr.update(value=read_persist_var("db_test"))
    h_l = gr.update(value=read_persist_var("history_len"))
    h_t = gr.update(value=read_persist_var("history_time"))
    m = gr.update(value=read_persist_var("max_tokens"))
    t = gr.update(value=read_persist_var("temperature"))
    r = gr.update(value=read_persist_var("reteriver_k"))
    r_f = gr.update(value=read_persist_var("reteriver_k_final"))
    r_r = gr.update(value=read_persist_var("reteriver_k_relate"))
    s_t = gr.update(value=read_persist_var("score_threshold"))
    return s, c, h, q, q_1, d, h_l, h_t, m, t, r, r_f, r_r, s_t
# å†™å…¥é…ç½®
def save_setting(chat_mode_choose, history_analyze, query_enhance, query_enhance_1, db_test):
    write_persist_var("chat_mode_choose", chat_mode_choose)
    write_persist_var("history_analyze", history_analyze)
    write_persist_var("query_enhance", query_enhance)
    write_persist_var("query_enhance_1", query_enhance_1)
    write_persist_var("db_test", db_test)
    gr.Info("å·²ä¿å­˜è‡³ API")
def save_setting_1(system_command, chat_mode_choose, history_analyze, query_enhance, query_enhance_1, db_test, history_len, history_time, max_tokens, temperature, reteriver_k, reteriver_k_final, reteriver_k_relate, score_threshold):
    write_persist_var("system_prompt", system_command)
    write_persist_var("chat_mode_choose", chat_mode_choose)
    write_persist_var("history_analyze", history_analyze)
    write_persist_var("query_enhance", query_enhance)
    write_persist_var("query_enhance_1", query_enhance_1)
    write_persist_var("db_test", db_test)
    write_persist_var("history_len", history_len)
    write_persist_var("history_time", history_time)
    write_persist_var("max_tokens", max_tokens)
    write_persist_var("temperature", temperature)
    write_persist_var("reteriver_k", reteriver_k)
    write_persist_var("reteriver_k_final", reteriver_k_final)
    write_persist_var("reteriver_k_relate", reteriver_k_relate)
    write_persist_var("score_threshold", score_threshold)
    gr.Info("å·²ä¿å­˜è‡³ APIï¼ˆ é‡å¯åç”Ÿæ•ˆ ï¼‰")
# æ£€ç´¢å‘é‡æ•°æ®åº“
def reterive_gr(id_input, reteriver_text, score_threshold_now, reterive_with_ai, db_choose):
    
    default_doc_value = "æš‚æ— ï¼Œè¯·å°è¯•æ£€ç´¢æˆ–ä¿®æ”¹é…ç½®åæ£€ç´¢ã€‚"
    doc, doc_1, doc_2, doc_3, doc_4, doc_5 = default_doc_value, default_doc_value, default_doc_value, default_doc_value, default_doc_value, default_doc_value

    if not id_input:
        gr.Warning("è¯·å†™å…¥ä¸´æ—¶å¯¹è¯ ID")
        return (
            gr.update(open=False), 
            gr.update(value=doc), 
            gr.update(open=False), 
            gr.update(value=doc_1), 
            gr.update(open=False), 
            gr.update(value=doc_2), 
            gr.update(open=False), 
            gr.update(value=doc_3), 
            gr.update(open=False), 
            gr.update(value=doc_4), 
        )
    
    if not reteriver_text and not messages.get(id_input, False): 
        gr.Warning("æœªæä¾›ç”¨äºæŸ¥è¯¢çš„ç›¸å…³å­—æ®µ")
        return (
            gr.update(open=False), 
            gr.update(value=doc), 
            gr.update(open=False), 
            gr.update(value=doc_1), 
            gr.update(open=False), 
            gr.update(value=doc_2), 
            gr.update(open=False), 
            gr.update(value=doc_3), 
            gr.update(open=False), 
            gr.update(value=doc_4), 
        )
    else:
        if db_choose == "Default":
            if score_threshold_now:
                if reterive_with_ai == "å¼€å¯":
                    docs = retrieve.invoke({"use_threshold": "yes", "score_threshold": score_threshold_now, "ai_check": "yes", "retrive": reteriver_text if reteriver_text else messages[id_input][-1][0]})
                else:
                    docs = retrieve.invoke({"use_threshold": "yes", "score_threshold": score_threshold_now, "retrive": reteriver_text if reteriver_text else messages[id_input][-1][0]})
            else:
                if reterive_with_ai == "å¼€å¯":
                    docs = retrieve.invoke({"ai_check": "yes", "retrive": reteriver_text if reteriver_text else messages[id_input][-1][0]})
                else:
                    docs = retrieve.invoke({"retrive": reteriver_text if reteriver_text else messages[id_input][-1][0]})
        else:
            if not test_read_all_file_record_key.invoke(""):
                gr.Info("æµ‹è¯•æ•°æ®åº“ç¼ºå°‘æ•°æ®")
                return (
                    gr.update(open=False), 
                    gr.update(value=doc), 
                    gr.update(open=False), 
                    gr.update(value=doc_1), 
                    gr.update(open=False), 
                    gr.update(value=doc_2), 
                    gr.update(open=False), 
                    gr.update(value=doc_3), 
                    gr.update(open=False), 
                    gr.update(value=doc_4), 
                )
            else:
                if score_threshold_now:
                    if reterive_with_ai == "å¼€å¯":
                        docs = retrieve.invoke({"choose": "test", "use_threshold": "yes", "score_threshold": score_threshold_now, "ai_check": "yes", "retrive": reteriver_text if reteriver_text else messages[id_input][-1][0]})
                    else:
                        docs = retrieve.invoke({"choose": "test", "use_threshold": "yes", "score_threshold": score_threshold_now, "retrive": reteriver_text if reteriver_text else messages[id_input][-1][0]})
                else:
                    if reterive_with_ai == "å¼€å¯":
                        docs = retrieve.invoke({"choose": "test", "ai_check": "yes", "retrive": reteriver_text if reteriver_text else messages[id_input][-1][0]})
                    else:
                        docs = retrieve.invoke({"choose": "test", "retrive": reteriver_text if reteriver_text else messages[id_input][-1][0]})
        
        for idx, doc_value in enumerate(docs):
            if idx == 0:
                doc = doc_value
            elif idx == 1:
                doc_1 = doc_value
            elif idx == 2:
                doc_2 = doc_value
            elif idx == 3:
                doc_3 = doc_value
            elif idx == 4:
                doc_4 = doc_value
            elif idx == 5:
                doc_5 = doc_value
        
        return (
            gr.update(open=True if len(docs) >=1 else False), 
            gr.update(value=doc), 
            gr.update(open=True if len(docs) >=2 else False), 
            gr.update(value=doc_1), 
            gr.update(open=True if len(docs) >=3 else False), 
            gr.update(value=doc_2), 
            gr.update(open=True if len(docs) >=4 else False), 
            gr.update(value=doc_3), 
            gr.update(open=True if len(docs) >=5 else False), 
            gr.update(value=doc_4)
        )
# ç®€æ˜“æ¨ç†
def simple_infer_gr(id_input, reply_for_you_prompt, temperature_now):

    if not id_input:
        gr.Warning("è¯·å†™å…¥ä¸´æ—¶å¯¹è¯ ID")
        return gr.update(value="æš‚æ— ï¼Œè¯·ç‚¹å‡» â€œç”Ÿæˆå›å¤â€")
    
    if not reply_for_you_prompt and not messages.get(id_input, False): 
        gr.Warning("æœªæä¾›ç”¨äºç”Ÿæˆå›å¤çš„ç›¸å…³å­—æ®µ")
        return gr.update(value="æš‚æ— ï¼Œè¯·ç‚¹å‡» â€œç”Ÿæˆå›å¤â€")
    else:
        reply = simple_infer.invoke({"input": reply_for_you_prompt if reply_for_you_prompt else messages[id_input][-1][0], "temperature": temperature_now})
        return gr.update(value=reply)
# å¯¹è¯åˆ†æ
def session_analyze_gr(id_input, history_analyze, analyze_show):

    noh = True if history_analyze == "å…³é—­" else False

    if streaming.get(id_input, False):
        return gr.update(value=analyze_show)
    
    if not id_input:
        gr.Warning("è¯·å†™å…¥ä¸´æ—¶å¯¹è¯ ID")
        return gr.update(value=analyze_show)
    
    if not messages.get(id_input, False): 
        gr.Warning("æ²¡æœ‰å¯ç”¨å†å²å¯¹è¯ä¿¡æ¯")
        return gr.update(value=analyze_show)
    else:
        if len(messages[id_input]) >= 3:
            analyze_answer = session_analyze_gr.invoke(
                {
                    "noh": noh, 
                    "input": f"å®¢æˆ·ï¼š{messages[id_input][-3][0]} {ai_name}ï¼š{messages[id_input][-3][1]} å®¢æˆ·ï¼š{messages[id_input][-2][0]} {ai_name}ï¼š{messages[id_input][-2][1]} å®¢æˆ·ï¼š{messages[id_input][-1][0]} {ai_name}ï¼š{messages[id_input][-1][1]}", 
                    "id": id_input, 
                    "from": "webui"
                }
            )
            return gr.update(value=analyze_answer)
        elif len(messages[id_input]) == 2:
            analyze_answer = session_analyze_gr.invoke(
                {
                    "noh": noh, 
                    "input": f"å®¢æˆ·ï¼š{messages[id_input][-2][0]} {ai_name}ï¼š{messages[id_input][-2][1]} å®¢æˆ·ï¼š{messages[id_input][-1][0]} {ai_name}ï¼š{messages[id_input][-1][1]}", 
                    "id": id_input, 
                    "from": "webui"
                }
            )
            return gr.update(value=analyze_answer)
        elif len(messages[id_input]) == 1:
            analyze_answer = session_analyze_gr.invoke(
                {
                    "noh": noh, 
                    "input": f"å®¢æˆ·ï¼š{messages[id_input][-1][0]} {ai_name}ï¼š{messages[id_input][-1][1]}", 
                    "id": id_input, 
                    "from": "webui"
                }
            )
            return gr.update(value=analyze_answer)
# é‡åˆ¶é…ç½®
def reset_setting():
    write_persist_var("system_prompt", init_system_prompt)
    write_persist_var("chat_mode_choose", "æ•°æ®åº“å¯¹è¯ï¼ˆ æ— é™åˆ¶ ï¼‰")
    write_persist_var("history_analyze", "å…³é—­")
    write_persist_var("query_enhance", "å…³é—­")
    write_persist_var("query_enhance_1", "å…³é—­")
    write_persist_var("db_test", "å…³é—­")
    write_persist_var("history_len", 3)
    write_persist_var("history_time", 7200)
    write_persist_var("max_tokens", 800)
    write_persist_var("temperature", 0)
    write_persist_var("reteriver_k", 20)
    write_persist_var("reteriver_k_final", 5)
    write_persist_var("reteriver_k_relate", 10)
    write_persist_var("score_threshold", 0.3)
    s = gr.update(value=read_persist_var("system_prompt"))
    c = gr.update(value=read_persist_var("chat_mode_choose"))
    h = gr.update(value=read_persist_var("history_analyze"))
    q = gr.update(value=read_persist_var("query_enhance"))
    q_1 = gr.update(value=read_persist_var("query_enhance_1"))
    d = gr.update(value=read_persist_var("db_test"))
    h_l = gr.update(value=read_persist_var("history_len"))
    h_t = gr.update(value=read_persist_var("history_time"))
    m = gr.update(value=read_persist_var("max_tokens"))
    t = gr.update(value=read_persist_var("temperature"))
    r = gr.update(value=read_persist_var("reteriver_k"))
    r_f = gr.update(value=read_persist_var("reteriver_k_final"))
    r_r = gr.update(value=read_persist_var("reteriver_k_relate"))
    s_t = gr.update(value=read_persist_var("score_threshold"))
    gr.Info("API è®¾ç½®å·²é‡åˆ¶ï¼ˆ é‡å¯åç”Ÿæ•ˆ ï¼‰")
    return s, c, h, q, q_1, d, h_l, h_t, m, t, r, r_f, r_r, s_t
# æ¸…é™¤å†å²å¯¹è¯
def clear_session(id_input):
    if not id_input:
        return [], [], ""
    else:
        clean_history.invoke({"id": id_input})
        if id_input in messages:
            del messages[id_input]
        else:
            pass
        clean_history.invoke({"id": f"dbtest_{id_input}"})
        if f"dbtest_{id_input}" in messages:
            del messages[f"dbtest_{id_input}"]
        else:
            pass
        return [], [], ""
# éŸ³é¢‘è½¬æ–‡æœ¬å¤„ç†ï¼ˆ å¯é—´æ¥æ¨ç† ï¼‰
def audio_text_gr(id_input, chatbot, audio_query, query, audio_check):
    if not id_input:
        gr.Warning("è¯·å†™å…¥ä¸´æ—¶å¯¹è¯ ID")
        return chatbot, query
    else:
        sr, y = audio_query
        y_list = [int(i) for i in y]
        if audio_check:
            text = audio_text.invoke({"sampling_rate": sr, "raw": y_list})
            return chatbot, text
        else:
            answer = audio_text.invoke({"with_infer": "yes", "sampling_rate": sr, "raw": y_list})
            
            if id_input in messages:
                messages[id_input].append(answer)
            else:
                messages[id_input] = [answer]
            
            return messages[id_input], query
# å¸¸è§„æ¨ç†ï¼ˆ æµå¼ä¼ è¾“ ï¼‰
def model_chat(id_input, db_test, chatbot, chatbot_1, query):

    if not id_input:
        gr.Warning("è¯·å†™å…¥ä¸´æ—¶å¯¹è¯ ID")
        return chatbot, chatbot_1, gr.update(interactive=True), query, gr.update(visible=False), gr.update(interactive=True), gr.update(interactive=True)
    elif "dbtest_" in id_input:
        gr.Warning("â€œdbtest_â€ æ˜¯ä¿ç•™å­—æ®µï¼Œè¯·åˆ é™¤")
        return chatbot, chatbot_1, gr.update(interactive=True), query, gr.update(visible=False), gr.update(interactive=True), gr.update(interactive=True)
    
    if not query:
        return chatbot, chatbot_1, gr.update(interactive=True), query, gr.update(visible=False), gr.update(interactive=True), gr.update(interactive=True)
    
    streaming[id_input] = True

    if id_input in messages:
        messages[id_input].append([query, f"{ai_name}æ­£åœ¨æ€è€ƒ..."])
    else:
        messages[id_input] = [[query, f"{ai_name}æ­£åœ¨æ€è€ƒ..."]]
    
    if db_test == "å¼€å¯":
        if manually_lock != 1:
            if test_read_all_file_record_key.invoke(""):
                streaming[f"dbtest_{id_input}"] = True
                if f"dbtest_{id_input}" in messages:
                    messages[f"dbtest_{id_input}"].append([query, f"{ai_name}æ­£åœ¨æ€è€ƒ..."])
                else:
                    messages[f"dbtest_{id_input}"] = [[query, f"{ai_name}æ­£åœ¨æ€è€ƒ..."]]
                return messages[id_input], messages[f"dbtest_{id_input}"], gr.update(interactive=False), gr.update(value="", visible=False), gr.update(visible=True), gr.update(interactive=False), gr.update(interactive=False)
            gr.Info("æµ‹è¯•æ•°æ®åº“ç¼ºå°‘æ•°æ®")
        gr.Warning("æµ‹è¯•æ•°æ®åº“æ­£åœ¨è¢«ä¿®æ”¹ï¼Œè¯·ç¨åé‡è¯•")
    return messages[id_input], [], gr.update(interactive=False), gr.update(value="", visible=False), gr.update(visible=True), gr.update(interactive=False), gr.update(interactive=False)
# ---
def model_chat_1(id_input, chat_mode_choose, history_analyze, query_enhance, query_enhance_1, chatbot):

    if not streaming.get(id_input, False):
        return chatbot

    # åˆå§‹åŒ–æ•°æ®
    noh = True if history_analyze == "å…³é—­" else False
    ctype = 2 if chat_mode_choose == chatmode[2] else 1 if chat_mode_choose == chatmode[1] else 0
    better_query = False if query_enhance == "å…³é—­" else True
    better_query_1 = False if query_enhance_1 == "å…³é—­" else True
    
    pre_work = infer.invoke(
        {
            "time": 1, 
            "noh": noh, 
            "ctype": ctype, 
            "input": messages[id_input][-1][0], 
            "id": id_input, 
            "better_query": better_query, 
            "better_query_1": better_query_1, 
            "from": "webui", 
            "llm": 0
        }
    )
    if not pre_work.get("stop", False):
        answer = infer.stream(
            {
                "time": 2, 
                "noh": noh, 
                "ctype": ctype, 
                "input": pre_work["input"], 
                "id": id_input, 
                "from": "webui", 
                "llm": 0
            }
        )
        messages[id_input][-1][1] = ""
        for character in answer:
            messages[id_input][-1][1] += character
            time.sleep(0.03)
            yield messages[id_input]
        messages[id_input][-1][1] = f"{messages[id_input][-1][1]}{plus_links.invoke({'id': id_input})}"
        yield messages[id_input]
    else:
        messages[id_input][-1][1] = pre_work["stop"]
        yield messages[id_input]
# ---
def model_chat_1_1(id_input, chat_mode_choose, history_analyze, query_enhance, query_enhance_1, chatbot):

    if not streaming.get(f"dbtest_{id_input}", False):
        return chatbot

    if chat_mode_choose == chatmode[0]:
        return chatbot
    
    # åˆå§‹åŒ–æ•°æ®
    noh = True if history_analyze == "å…³é—­" else False
    ctype = 2 if chat_mode_choose == chatmode[2] else 1 if chat_mode_choose == chatmode[1] else 0
    better_query = False if query_enhance == "å…³é—­" else True
    better_query_1 = False if query_enhance_1 == "å…³é—­" else True
    
    pre_work = infer.invoke(
        {
            "time": 1, 
            "noh": noh, 
            "ctype": ctype, 
            "input": messages[id_input][-1][0], 
            "id": f"dbtest_{id_input}", 
            "better_query": better_query, 
            "better_query_1": better_query_1, 
            "from": "webui", 
            "llm": 0
        }
    )
    if not pre_work.get("stop", False):
        answer = infer.stream(
            {
                "time": 2, 
                "noh": noh, 
                "ctype": ctype, 
                "input": pre_work["input"], 
                "id": f"dbtest_{id_input}", 
                "from": "webui", 
                "llm": 0
            }
        )
        messages[id_input][-1][1] = ""
        for character in answer:
            messages[id_input][-1][1] += character
            time.sleep(0.03)
            yield messages[id_input]
        messages[id_input][-1][1] = f"{messages[id_input][-1][1]}{plus_links.invoke({'id': id_input})}"
        yield messages[id_input]
    else:
        messages[id_input][-1][1] = pre_work["stop"]
        yield messages[id_input]
# ---
def model_chat_2(id_input, query_1):
    # audio = gr.update(value=None)
    if streaming.get(id_input, False):
        # audio = audio_generator.invoke({"text": messages[id_input][-1][0]})
        del streaming[id_input]
    if streaming.get(f"dbtest_{id_input}", False):
        del streaming[f"dbtest_{id_input}"]
    return (
        # (audio[0], np.array(audio[1])), 
        gr.update(interactive=True), 
        gr.update(value=query_1, visible=True), 
        gr.update(value="", visible=False), 
        gr.update(interactive=True), 
        gr.update(interactive=True)
    )
# æŸ¥çœ‹ ID å¯¹åº”å¯¹è¯
def history_watch(history_choose):
    if history_choose in list(messages.keys()):
        return messages[history_choose]
    else:
        return []
# å¯¹è¯åˆ·æ–°åŠŸèƒ½ï¼ˆ ä¸´æ—¶å¯¹è¯ç®¡ç† ï¼‰
def refresh_watch(history_choose):
    new_history_chooses = gr.update(choices=get_ids())
    if id_input in messages:
        return new_history_chooses, messages[history_choose]
    else:
        return new_history_chooses, []
# Tab åˆ·æ–°åŠŸèƒ½ï¼ˆ ä¸´æ—¶å¯¹è¯ç®¡ç† ï¼‰
def refresh_tab_watch():
    new_history_chooses = gr.update(choices=get_ids(), value=None)
    return new_history_chooses, []
# å†å²å¯¹è¯åˆ é™¤ï¼ˆ ä¸´æ—¶å¯¹è¯ç®¡ç† ï¼‰
def del_history(history_choose, chatbot_2):

    if streaming.get(history_choose, False):
        gr.Warning("é€‰ä¸­å¯¹è¯ç”Ÿåœ¨ç”Ÿæˆå›å¤ï¼Œè¯·ç¨åé‡è¯•")
        return history_choose, chatbot_2
    
    new_history_chooses = gr.update(choices=get_ids(), value=None)

    if history_choose in list(messages.keys()):
        clean_history.invoke({"id": history_choose})
        del messages[history_choose]
        return new_history_chooses, []
    else:
        return new_history_chooses, []
# å‘é‡æ•°æ®åº“åˆ·æ–°åŠŸèƒ½
def refresh_db_watch():
    with lock:
        with lock_1:
            return gr.update(value=read_all_file_record_key()), gr.update(value=test_read_all_file_record_key.invoke("")), gr.update(choices=list(read_persist_var("ç»†åŒ–å…³é”®è¯").keys()), value=None), gr.update(choices=[], value=None)
# æ–‡ä»¶ä¸Šä¼ 
def upload_process_gr(file_upload_path):
    with lock:
        gr.Info("æ–°çš„ä¿®æ”¹å°†åœ¨é‡å¯æœåŠ¡åç”Ÿæ•ˆ")
        return gr.update(value=upload_process.invoke(file_upload_path))
# æ–‡ä»¶ä¸Šä¼ ï¼ˆ æµ‹è¯•æ•°æ®åº“ä¸“ç”¨ )
def test_upload_process_gr(test_file_upload_path):
    global manually_lock
    with lock:
        if any(value for key, value in streaming.items() if key.startswith("dbtest_")):
            gr.Warning("æµ‹è¯•æ•°æ®åº“æ­£åœ¨è¢«è¯»å–ï¼Œè¯·ç¨åé‡è¯•")
            return test_read_all_file_record_key.invoke("")
        manually_lock = 1
        t_u_p = gr.update(value=test_upload_process.invoke(test_file_upload_path))
        manually_lock = 0
        return t_u_p
# å…¨éƒ¨æ–‡ä»¶åˆ é™¤ï¼ˆ æµ‹è¯•æ•°æ®åº“ä¸“ç”¨ ï¼‰
def test_del_all_file_process_gr():
    global manually_lock
    with lock:
        if any(value for key, value in streaming.items() if key.startswith("dbtest_")):
            gr.Warning("æµ‹è¯•æ•°æ®åº“æ­£åœ¨è¢«è¯»å–ï¼Œè¯·ç¨åé‡è¯•")
            return test_read_all_file_record_key.invoke("")
        manually_lock = 1
        t_d_a_f_p = gr.update(value=test_del_all_file_process.invoke(""))
        manually_lock = 0
        return t_d_a_f_p
# æ–‡ä»¶åˆ é™¤
def del_file_process_gr(del_on, del_file):
    with lock:
        if del_on == "Default":
            doc_path = f"{vector_original_path}/{del_file}.md"
            # æ ¡éªŒæ–‡ä»¶å­˜åœ¨ä¸å¦ï¼Œé˜²æ­¢åˆ é™¤æœ¬å·²ä¸å­˜åœ¨çš„æ–‡ä»¶åæŠ¥é”™
            if doc_path in read_all_file_record_key():
                if len(read_all_file_record_key()) == 1:
                    gr.Info("è¯·ç¡®ä¿æ•°æ®åº“å†…è‡³å°‘å­˜åœ¨ä¸€ä¸ªæ–‡ä»¶")
                    return del_file, gr.update(value=read_all_file_record_key()), gr.update(value=test_read_all_file_record_key.invoke(""))
                else:
                    gr.Info("æ–°çš„ä¿®æ”¹å°†åœ¨é‡å¯æœåŠ¡åç”Ÿæ•ˆ")
                    return "", gr.update(value=del_file_process.invoke(doc_path)), gr.update(value=test_read_all_file_record_key.invoke(""))
            else:
                gr.Info("æ— åŒ¹é…æ–‡ä»¶ï¼ˆ å¯èƒ½å·²è¢«åˆ é™¤ ï¼‰")
                return del_file, gr.update(value=read_all_file_record_key()), gr.update(value=test_read_all_file_record_key.invoke(""))
        elif del_on == "Test":
            global manually_lock
            # æ ¡éªŒæ–‡ä»¶å­˜åœ¨ä¸å¦ï¼Œé˜²æ­¢åˆ é™¤æœ¬å·²ä¸å­˜åœ¨çš„æ–‡ä»¶åæŠ¥é”™
            found_path = False
            for doc_path in test_read_all_file_record_key.invoke(""):
                if doc_path.endswith(del_file):
                    found_path = doc_path
                    break
            if found_path:
                if found_path in test_read_all_file_record_key.invoke(""):
                    if len(test_read_all_file_record_key.invoke("")) == 1:
                        gr.Info("è¯·ç¡®ä¿æ•°æ®åº“å†…è‡³å°‘å­˜åœ¨ä¸€ä¸ªæ–‡ä»¶")
                        return del_file, gr.update(value=read_all_file_record_key()), gr.update(value=test_read_all_file_record_key.invoke(""))
                    else:
                        if manually_lock != 2:
                            manually_lock = 1
                            t_d_f_p = gr.update(value=test_del_file_process.invoke(found_path))
                            manually_lock = 0
                            return "", gr.update(value=read_all_file_record_key()), t_d_f_p
                        else:
                            gr.Warning("æµ‹è¯•æ•°æ®åº“æ­£åœ¨è¢«è¯»å–ï¼Œè¯·ç¨åé‡è¯•")
                            return "", gr.update(value=read_all_file_record_key()), test_read_all_file_record_key.invoke("")
            else:
                gr.Info("æ— åŒ¹é…æ–‡ä»¶ï¼ˆ å¯èƒ½å·²è¢«åˆ é™¤ ï¼‰")
                return del_file, gr.update(value=read_all_file_record_key()), gr.update(value=test_read_all_file_record_key.invoke(""))
# æŸ¥çœ‹å¯¹åº”å­å…³é”®è¯
def keyword_list(simple_keyword_choose):
    with lock_1:
        return gr.update(choices=list(read_persist_var("ç»†åŒ–å…³é”®è¯")[simple_keyword_choose].keys()), value=None)
# æå–å…³é”®è¯è¯´æ˜
def load_tip(simple_keyword_choose, keyword_choose):
    with lock_1:
        value = read_persist_var("ç»†åŒ–å…³é”®è¯")[simple_keyword_choose][keyword_choose].replace("ï¼ˆ", "").replace("ï¼‰", "")
        if value:
            return gr.update(placeholder=f"ä¸€æ®µç²¾ç®€çš„æ–‡å­—ç”¨äºæè¿°å­å…³é”®è¯ã€‚\nå½“å‰ï¼š{value}")
        else:
            return gr.update(placeholder=f"ä¸€æ®µç²¾ç®€çš„æ–‡å­—ç”¨äºæè¿°å­å…³é”®è¯ã€‚\nå½“å‰ï¼šæ— ")
# å°†å…³é”®è¯ä»¥å›ºå®šæ ¼å¼åŠ è½½è‡³æ–‡æœ¬æ¡†ï¼ˆ æ–¹ä¾¿å¤å†™æ–°å…³é”®è¯ ï¼‰
def keywords_load(simple_keyword_choose):
    with lock_1:
        return gr.update(value=f"{simple_keyword_choose} {' '.join(key for key in read_persist_var('ç»†åŒ–å…³é”®è¯')[simple_keyword_choose].keys())}")
# å®šä¹‰åˆ é™¤çˆ¶å…³é”®è¯
def del_simple_keyword(simple_keyword_choose):
    with lock_1:
        if simple_keyword_choose in read_persist_var("ç»†åŒ–å…³é”®è¯"):
            with shelve.open(f"{config_path}/persist_var") as pvar_db:
                gr.Info("æ–°çš„ä¿®æ”¹å°†åœ¨é‡å¯æœåŠ¡åç”Ÿæ•ˆ")
                copy = pvar_db["ç»†åŒ–å…³é”®è¯"]
                del copy[simple_keyword_choose]
                pvar_db["ç»†åŒ–å…³é”®è¯"] = copy
        return gr.update(choices=list(read_persist_var("ç»†åŒ–å…³é”®è¯").keys()), value=None), gr.update(choices=[], value=None)
# åˆ é™¤å­å…³é”®è¯
def del_keyword(simple_keyword_choose, keyword_choose):
    with lock_1:
        if keyword_choose in read_persist_var("ç»†åŒ–å…³é”®è¯")[simple_keyword_choose]:
            with shelve.open(f"{config_path}/persist_var") as pvar_db:
                gr.Info("æ–°çš„ä¿®æ”¹å°†åœ¨é‡å¯æœåŠ¡åç”Ÿæ•ˆ")
                copy = pvar_db["ç»†åŒ–å…³é”®è¯"]
                del copy[simple_keyword_choose][keyword_choose]
                pvar_db["ç»†åŒ–å…³é”®è¯"] = copy
        return gr.update(choices=list(read_persist_var("ç»†åŒ–å…³é”®è¯")[simple_keyword_choose].keys()), value=None)
# å…³é”®è¯ä¿®æ”¹ä¿å­˜
def keyword_save(simple_keyword_choose, keyword_choose, tip, create_keywords):
    with lock_1:
        if create_keywords:
            words = create_keywords.split()
            keyword_dict = {}
            for word in words[1:]:
                keyword_dict[word] = "æ— "
            with shelve.open(f"{config_path}/persist_var") as pvar_db:
                gr.Info("æ–°çš„ä¿®æ”¹å°†åœ¨é‡å¯æœåŠ¡åç”Ÿæ•ˆ")
                copy = pvar_db["ç»†åŒ–å…³é”®è¯"]
                copy[words[0]] = keyword_dict
                pvar_db["ç»†åŒ–å…³é”®è¯"] = copy
        if tip:
            if keyword_choose:
                if simple_keyword_choose in read_persist_var("ç»†åŒ–å…³é”®è¯"):
                    if keyword_choose in read_persist_var("ç»†åŒ–å…³é”®è¯")[simple_keyword_choose]:
                        with shelve.open(f"{config_path}/persist_var") as pvar_db:
                            gr.Info("æ–°çš„ä¿®æ”¹å°†åœ¨é‡å¯æœåŠ¡åç”Ÿæ•ˆ")
                            copy = pvar_db["ç»†åŒ–å…³é”®è¯"]
                            copy[simple_keyword_choose][keyword_choose] = f"ï¼ˆ{tip}ï¼‰"
                            pvar_db["ç»†åŒ–å…³é”®è¯"] = copy
                        return simple_keyword_choose, keyword_choose, gr.update(value=None), gr.update(value=None)
            gr.Info("æ— åŒ¹é…å­å…³é”®è¯ï¼ˆ å¯èƒ½å·²è¢«åˆ é™¤ ï¼‰")
            return gr.update(choices=list(read_persist_var("ç»†åŒ–å…³é”®è¯").keys()), value=None), gr.update(choices=[], value=None), tip, gr.update(value=None)
        return gr.update(choices=list(read_persist_var("ç»†åŒ–å…³é”®è¯").keys()), value=None), gr.update(choices=[], value=None), tip, gr.update(value=None)


# Gradio WebUI
######################################################
if __name__ == "__main__":
    with gr.Blocks(title=f"{ai_name} AI") as tweaks:  # css="footer{display:none !important}"
        gr.Markdown(f"""<p align="center"><img src="file/{sign_path}" style="height: 188px"/><p>""")
        gr.Markdown(f"""<center><font size=8>{project_name} ğŸ’¬</center>""")
        gr.Markdown(f"""<center><font size=4>å½“å‰å‚æ•°è§„æ¨¡ï¼š{weight_size}</center>""")

        with gr.Tabs():
            with gr.Tab("æµ‹è¯•ç¯å¢ƒ"):
                with gr.Row():
                    with gr.Column(scale=1):
                        # gr.Textbox(label='ğŸ“¢', value="å½“æ£€æµ‹ä¸åˆ°éº¦å…‹é£æˆ–æ— æ³•è§¦å‘å¤åˆ¶æ§ä»¶ï¼Œä¸”ä½¿ç”¨ Chorme æ—¶ï¼Œè¯·æ‰“å¼€ä¸‹æ–¹é“¾æ¥å¹¶å°†å½“å‰åœ°å€å¡«å…¥åé€‰æ‹© â€œEnabledâ€ã€‚\n\nchrome://flags/#unsafely-treat-insecure-origin-as-secure", interactive=False, show_copy_button=True)
                        # with gr.Accordion(label="ä¸´æ—¶é…ç½®", open=True): 
                        id_input = gr.Textbox(label='å¯¹è¯ ID', placeholder="è¯·å†™å…¥ç”¨äºä¸´æ—¶è®°å½•å¯¹è¯çš„ ID")
                        chat_mode_choose = gr.Radio(
                            choices=chatmode, 
                            label="å¯¹è¯æ¨¡å¼", 
                            value=chatmode[2], 
                            interactive=True
                        )
                        # history_analyze åœ¨æ–°ä¸€è½®å¯¹è¯ä¸­å°†å†å²å¯¹è¯åµŒå…¥ Prompt ä¸­
                        # session_analyze è®© AI é’ˆå¯¹å…ˆå‰å¯¹è¯æå‡ºå»ºè®®
                        history_analyze = gr.Radio(
                            choices=["å¼€å¯","å…³é—­"], 
                            label="å†å²åˆ†æ", 
                            value="å…³é—­", 
                            interactive=True
                        )
                        query_enhance = gr.Radio(
                            choices=["å¼€å¯","å…³é—­"], 
                            label="è¯¢é—®é€»è¾‘ä¼˜åŒ–", 
                            value="å…³é—­", 
                            interactive=True
                        )
                        query_enhance_1 = gr.Radio(
                            choices=["å¼€å¯","å…³é—­"], 
                            label="è¯¢é—®å…³é”®è¯ä¼˜åŒ–", 
                            value="å…³é—­", 
                            interactive=True
                        )
                        db_test = gr.Radio(
                            choices=["å¼€å¯","å…³é—­"], 
                            label="æ•°æ®åº“æµ‹è¯•", 
                            value="å…³é—­", 
                            interactive=True
                        )
                        save = gr.Button(value="ä¿å­˜è‡³æ¥å£")
                        load = gr.Button(value="ä»æ¥å£åŠ è½½")
                    with gr.Column(scale=3):
                        with gr.Row():
                            # render_markdown=False
                            chatbot = gr.Chatbot(label='Default', show_copy_button=True)
                            chatbot_1 = gr.Chatbot(label='Test', show_copy_button=True, visible=False)
                        audio_answer = gr.Audio(label="éŸ³é¢‘å›å¤ï¼ˆ åŠŸèƒ½æµ‹è¯•ä¸­ ï¼‰", interactive=False)
                        with gr.Column():
                            with gr.Tabs():
                                with gr.Tab("å¯¹è¯å°å…‰"):
                                    audio_query = gr.Audio(sources=["microphone"], label='éŸ³é¢‘è¯¢é—®')
                                    query = gr.Textbox(lines=2, label='æ–‡æœ¬è¯¢é—®', placeholder="æ¢è¡Œï¼šEnterï½œå‘é€æ¶ˆæ¯ï¼šShift + Enter")
                                    query_1 = gr.Textbox(lines=2, label='æ–‡æœ¬è¯¢é—®', placeholder="è¯·ç­‰å¾…å›å¤ç»“æŸ", visible=False)
                                    with gr.Row():
                                        audio_check = gr.Checkbox(value=False, label='éŸ³é¢‘è½¬æ–‡æœ¬', interactive=True)
                                        clear_history = gr.Button(value="æ¸…é™¤å†å²")
                                        sumbit = gr.Button(value="å‘é€è¯¢é—®", variant="primary")
                                with gr.Tab("æ•°æ®åº“æ£€ç´¢"):
                                    with gr.Accordion(label="æ–‡æ¡£æ£€ç´¢ï¼ˆ è¯­æ„æ£€ç´¢ ï¼‰", open=True): 
                                        with gr.Row():
                                            with gr.Column():
                                                reteriver_text = gr.Textbox(lines=2, placeholder="ç•™ç©ºé»˜è®¤ä½¿ç”¨æœ€æ–°è¯¢é—®ï¼ˆ Default çª—å£ ï¼‰æ£€ç´¢æ–‡æ¡£ï¼Œåä¹‹ä½¿ç”¨å¡«å…¥æ–‡æœ¬æ£€ç´¢æ–‡æ¡£ã€‚", container=False)
                                                with gr.Accordion(label='æ–‡æ¡£ä¸€', open=False) as doc_show: 
                                                    doc = gr.Markdown(value="æš‚æ— ï¼Œè¯·å°è¯•æ£€ç´¢æˆ–ä¿®æ”¹é…ç½®åæ£€ç´¢ã€‚")
                                                with gr.Accordion(label='æ–‡æ¡£äºŒ', open=False) as doc_show_1: 
                                                    doc_1 = gr.Markdown(value="æš‚æ— ï¼Œè¯·å°è¯•æ£€ç´¢æˆ–ä¿®æ”¹é…ç½®åæ£€ç´¢ã€‚")
                                                with gr.Accordion(label='æ–‡æ¡£ä¸‰', open=False) as doc_show_2: 
                                                    doc_2 = gr.Markdown(value="æš‚æ— ï¼Œè¯·å°è¯•æ£€ç´¢æˆ–ä¿®æ”¹é…ç½®åæ£€ç´¢ã€‚")
                                                with gr.Accordion(label='æ–‡æ¡£å››', open=False) as doc_show_3: 
                                                    doc_3 = gr.Markdown(value="æš‚æ— ï¼Œè¯·å°è¯•æ£€ç´¢æˆ–ä¿®æ”¹é…ç½®åæ£€ç´¢ã€‚")
                                                with gr.Accordion(label='æ–‡æ¡£äº”', open=False) as doc_show_4: 
                                                    doc_4 = gr.Markdown(value="æš‚æ— ï¼Œè¯·å°è¯•æ£€ç´¢æˆ–ä¿®æ”¹é…ç½®åæ£€ç´¢ã€‚")
                                            with gr.Column():
                                                score_threshold_now = gr.Slider(minimum=0, maximum=1, value=0, step=0.1, label="ç›¸ä¼¼é˜ˆå€¼ï¼ˆ 0 ä¸ºæ— é˜€å€¼ï¼›å¦‚éœ€ä½¿ç”¨ 0.3 ä¸ºå»ºè®®å€¼ ï¼‰", interactive=True)
                                                reterive_with_ai = gr.Radio(
                                                    choices=["å…³é—­", "å¼€å¯"], 
                                                    label="å°å…‰ BUFFï¼ˆ åˆ©ç”¨ AI äºŒæ¬¡æ£€ç´¢æ–‡æ¡£ ï¼‰", 
                                                    value="å…³é—­", 
                                                    interactive=True
                                                )                                
                                                with gr.Row():
                                                    db_choose = gr.Radio(
                                                        choices=["Default", "Test"], 
                                                        value="Default", 
                                                        show_label=False, 
                                                        interactive=True
                                                    )
                                                    start_reterive = gr.Button(value="æ£€ç´¢å¯¹åº”æ•°æ®åº“")
                                with gr.Tab("å¯¹æ¥ç›¸å…³"):
                                    with gr.Column():
                                        with gr.Accordion(label="ç‰¹å¾åˆ†æï¼ˆ è½¬äººå·¥æ—¶é¢å‘å¯¹æ¥äººå‘˜å•æ¬¡è§¦å‘ ï¼‰", open=True):  
                                            features_analyze = gr.Markdown(value="è½¬äººå·¥é€šå¸¸ä»£è¡¨å°å…‰å¯èƒ½æœªè§£å†³å…¶é—®é¢˜ï¼ˆ æ•°æ®åº“ä¸å…¨æˆ–è€…å°å…‰åˆ†ææœ‰è¯¯ ï¼‰ï¼Œ<br/>å› æ­¤ç‰¹å¾åˆ†ææ—¶å°†ä¸å‚è€ƒæ•°æ®åº“ã€‚")
                                            gr.Textbox(value="ç”±å°å…‰é’ˆå¯¹å¯¹è¯åˆ†æåï¼Œæä¾›äº›è®¸å…³é”®æ€§å»ºè®®", interactive=False, container=False)
                                        with gr.Accordion(label="å›å¤å»ºè®®", open=True): 
                                            reply_for_you_prompt = gr.Textbox(lines=2, placeholder="ç•™ç©ºé»˜è®¤ä½¿ç”¨ç”¨æˆ·æœ€æ–°è¯¢é—®ï¼ˆ Default çª—å£ ï¼‰ç”Ÿæˆå›å¤ï¼Œåä¹‹ä½¿ç”¨å¡«å…¥æ–‡æœ¬ç”Ÿæˆå›å¤ã€‚", container=False)
                                            with gr.Accordion(label='å›å¤å†…å®¹ï¼š', open=True): 
                                               reply_for_you = gr.Markdown(value="æš‚æ— å†…å®¹ï¼Œè¯·ç‚¹å‡» â€œç”Ÿæˆå›å¤â€ æŒ‰é’®")
                                        with gr.Row():
                                            with gr.Column(scale=3):
                                                temperature_now = gr.Slider(minimum=0, maximum=1, value=0, step=0.1, label="Temperatureï¼ˆ å€¼è¶Šé«˜å›å¤éšæœºæ€§è¶Šé«˜ )", interactive=True)
                                            reply_for_you_start = gr.Button(value="ç”Ÿæˆå›å¤")
                                            features_analyze_start = gr.Button(value="ç”Ÿæˆåˆ†æ")

                chat_mode_choose.input(
                    fn=dected_del, 
                    inputs=[id_input], 
                    outputs=[chatbot, chatbot_1, query]
                )
                history_analyze.input(
                    fn=dected_del, 
                    inputs=[id_input], 
                    outputs=[chatbot, chatbot_1, query]
                )
                query_enhance.input(
                    fn=chatgpt_info, 
                    inputs=[], 
                    outputs=[]
                )
                query_enhance_1.input(
                    fn=chatgpt_info, 
                    inputs=[], 
                    outputs=[]
                )
                db_test.input(
                    fn=test_db, 
                    inputs=[id_input, db_test], 
                    outputs=[chatbot, chatbot_1, query]
                )

                save.click(
                    fn=save_setting, 
                    inputs=[chat_mode_choose, history_analyze, query_enhance, query_enhance_1, db_test], 
                    outputs=[]
                )
                load.click(
                    fn=load_from_api,
                    inputs=[id_input, chat_mode_choose, history_analyze, db_test, query, chatbot],
                    outputs=[chat_mode_choose, history_analyze, query_enhance, query_enhance_1, db_test, query, chatbot, chatbot_1]
                )

                start_reterive.click(
                    fn=reterive_gr, 
                    inputs=[id_input, reteriver_text, score_threshold_now, reterive_with_ai, db_choose], 
                    outputs=[doc_show, doc, doc_show_1, doc_1, doc_show_2, doc_2, doc_show_3, doc_3, doc_show_4, doc_4]
                )
                reply_for_you_start.click(
                    fn=simple_infer_gr, 
                    inputs=[id_input, reply_for_you_prompt, temperature_now], 
                    outputs=[reply_for_you]
                )
                features_analyze_start.click(
                    fn=session_analyze_gr, 
                    inputs=[id_input, history_analyze, features_analyze], 
                    outputs=[features_analyze]
                )

                audio_query.stop_recording(
                    fn=audio_text_gr, 
                    inputs=[id_input, chatbot, audio_query, query, audio_check],
                    outputs=[chatbot, query]
                )
                query.submit(
                    fn=model_chat, 
                    inputs=[id_input, db_test, chatbot, chatbot_1, query], 
                    outputs=[chatbot, chatbot_1, audio_query, query, query_1, clear_history, sumbit]
                ).then(
                    fn=model_chat_1, 
                    inputs=[id_input, chat_mode_choose, history_analyze, query_enhance, query_enhance_1, chatbot], 
                    outputs=[chatbot]
                ).then(
                    fn=model_chat_1_1, 
                    inputs=[id_input, chat_mode_choose, history_analyze, query_enhance, query_enhance_1, chatbot], 
                    outputs=[chatbot_1]
                ).then(
                    fn=model_chat_2, 
                    inputs=[id_input, query_1], 
                    outputs=[audio_answer, audio_query, query, query_1, clear_history, sumbit]
                )
                
                clear_history.click(fn=clear_session,inputs=[id_input],outputs=[chatbot, chatbot_1, query])
                
                sumbit.click(
                    fn=model_chat, 
                    inputs=[id_input, db_test, chatbot, chatbot_1, query], 
                    outputs=[chatbot, chatbot_1, audio_query, query, query_1, clear_history, sumbit]
                ).then(
                    fn=model_chat_1, 
                    inputs=[id_input, chat_mode_choose, history_analyze, query_enhance, query_enhance_1, chatbot], 
                    outputs=[chatbot]
                ).then(
                    fn=model_chat_1_1, 
                    inputs=[id_input, chat_mode_choose, history_analyze, query_enhance, query_enhance_1, chatbot], 
                    outputs=[chatbot_1]
                ).then(
                    fn=model_chat_2, 
                    inputs=[id_input, query_1], 
                    outputs=[audio_answer, audio_query, query, query_1, clear_history, sumbit]
                )

            with gr.Tab("ä¸´æ—¶å¯¹è¯æŸ¥çœ‹") as history_tweak:
                with gr.Column():
                    history_choose = gr.Radio(
                        choices=get_ids(), 
                        label="ID é€‰æ‹©", 
                        interactive=True, 
                    )
                    chatbot_2 = gr.Chatbot(label='å†å²å¯¹è¯', show_copy_button=True)
                    with gr.Row():
                        refresh = gr.Button(value="åˆ·æ–°")                           
                        del_session = gr.Button(value="åˆ é™¤æ­¤å¯¹è¯")

                history_tweak.select(
                    fn=refresh_tab_watch, 
                    inputs=[], 
                    outputs=[history_choose, chatbot_2]
                )
                
                history_choose.input(
                    fn=history_watch, 
                    inputs=[history_choose], 
                    outputs=[chatbot_2]
                )
                
                refresh.click(
                    fn=refresh_watch, 
                    inputs=[history_choose], 
                    outputs=[history_choose, chatbot_2]
                )
                
                del_session.click(
                    fn=del_history, 
                    inputs=[history_choose, chatbot_2], 
                    outputs=[history_choose, chatbot_2]
                )

            with gr.Tab("æ•°æ®åº“ç®¡ç†") as database_tweak:
                with gr.Row():
                    with gr.Column(scale=3):
                        vectordb_file = gr.File(label="Default", value=read_all_file_record_key(), file_types=[".md"], interactive=False)
                        file_upload_button = gr.UploadButton(label="ç‚¹å‡»ä¸Šä¼  .md æ–‡ä»¶", file_types=[".md"], interactive=True)
                        test_vectordb_file = gr.File(label="Test", value=[], file_types=[".md"], interactive=True)
                        test_file_upload_button = gr.UploadButton(label="ç‚¹å‡»ä¸Šä¼  .md æ–‡ä»¶", file_types=[".md"], interactive=True)
                    with gr.Column(scale=1):
                        with gr.Accordion(label="è°¨æ…æ“ä½œ", open=False): 
                            del_file_on = gr.Radio(
                                choices=["Default", "Test"], 
                                label="ä½œç”¨åŸŸ", 
                                value="Default", 
                                interactive=True
                            )
                            del_file = gr.Textbox(label="åˆ é™¤å•ä¸ªæ–‡ä»¶ï¼ˆ è°¨æ…æ“ä½œ ï¼‰", placeholder="æ­¤æ“ä½œä¸å¯é€†ï¼ˆ æ— éœ€åç¼€å ï¼‰")
                            del_confirm = gr.Button(value="ç¡®è®¤åˆ é™¤")
                        with gr.Accordion(label="å…³é”®è¯ç¼–è¾‘å™¨", open=False): 
                            simple_keyword_choose = gr.Radio(
                                choices=list(read_persist_var("ç»†åŒ–å…³é”®è¯").keys()), 
                                label="çˆ¶å…³é”®è¯", 
                                interactive=True, 
                            )
                            keyword_choose = gr.Radio(
                                choices=["æ— "], 
                                label="å­å…³é”®è¯", 
                                interactive=True, 
                            )
                            tip = gr.Textbox(lines=2, label='ç²¾ç®€è¯´æ˜', placeholder="ä¸€æ®µç²¾ç®€çš„æ–‡å­—ç”¨äºæè¿°å­å…³é”®è¯ã€‚\nå½“å‰ï¼šæ— ")
                            create_keywords = gr.Textbox(lines=5, label='æ–°å¢å…³é”®è¯ç»„ï¼ˆ ä¸ç°æœ‰é‡å¤è§†ä¸ºä¿®æ”¹ ï¼‰', placeholder="æ ¼å¼ï¼šé¦–è¯ç»„å°†è§†ä¸ºçˆ¶å…³é”®è¯ï¼Œå…¶å®ƒè§†ä¸ºå­å…³é”®è¯ï¼Œå½¼æ­¤ä¹‹é—´ä»¥ç©ºæ ¼ç›¸éš”ã€‚\næ ·æœ¬ï¼šåŠ é€Ÿ æˆ˜æ–—åŠ é€Ÿå™¨ ç½‘ç»œåŠ é€Ÿå™¨\næç¤ºï¼šå­å…³é”®è¯è¯´æ˜è¯·åœ¨åˆ›å»ºåé€‰ä¸­å…³é”®è¯æ·»åŠ ï¼ˆ è¯´æ˜å¯ä½¿ AI ä¼˜åŒ–è¯¢é—®æ—¶æ›´å‡†ç¡® ï¼‰")
                            load_keywords = gr.Button(value="åŠ è½½é€‰ä¸­è‡³æ–°å¢")
                            simple_keyword_del = gr.Button(value="åˆ é™¤é€‰ä¸­çˆ¶å…³é”®è¯")
                            keyword_del = gr.Button(value="åˆ é™¤é€‰ä¸­å­å…³é”®è¯")
                            save_changes = gr.Button(value="ä¿å­˜è¯´æ˜æˆ–è¯ç»„")
                        refresh_db = gr.Button(value="åˆ·æ–°é¡µé¢")

                database_tweak.select(
                    fn=refresh_db_watch,
                    inputs=[],
                    outputs=[vectordb_file, test_vectordb_file, simple_keyword_choose, keyword_choose]
                )
                
                file_upload_button.upload(
                    fn=upload_process_gr, 
                    inputs=[file_upload_button], 
                    outputs=[vectordb_file]
                )
                
                test_vectordb_file.upload(
                    fn=test_upload_process_gr, 
                    inputs=[test_vectordb_file], 
                    outputs=[test_vectordb_file]
                )
                
                test_vectordb_file.clear(
                    fn=test_del_all_file_process_gr, 
                    inputs=[], 
                    outputs=[test_vectordb_file]
                )
                
                test_file_upload_button.upload(
                    fn=test_upload_process_gr, 
                    inputs=[test_file_upload_button], 
                    outputs=[test_vectordb_file]
                )
                
                del_confirm.click(
                    fn=del_file_process_gr, 
                    inputs=[del_file_on, del_file], 
                    outputs=[del_file, vectordb_file, test_vectordb_file]
                )
                
                simple_keyword_choose.input(
                    fn=keyword_list, 
                    inputs=[simple_keyword_choose], 
                    outputs=[keyword_choose]
                )
                
                keyword_choose.input(
                    fn=load_tip, 
                    inputs=[simple_keyword_choose, keyword_choose], 
                    outputs=[tip]
                )
                
                load_keywords.click(
                    fn=keywords_load, 
                    inputs=[simple_keyword_choose], 
                    outputs=[create_keywords]
                )
                
                simple_keyword_del.click(
                    fn=del_simple_keyword, 
                    inputs=[simple_keyword_choose], 
                    outputs=[simple_keyword_choose, keyword_choose]
                )
                
                keyword_del.click(
                    fn=del_keyword, 
                    inputs=[simple_keyword_choose, keyword_choose], 
                    outputs=[keyword_choose]
                )
                
                save_changes.click(
                    fn=keyword_save, 
                    inputs=[simple_keyword_choose, keyword_choose, tip, create_keywords], 
                    outputs=[simple_keyword_choose, keyword_choose, tip, create_keywords]
                )
                
                refresh_db.click(
                    fn=refresh_db_watch,
                    inputs=[],
                    outputs=[vectordb_file, test_vectordb_file, simple_keyword_choose, keyword_choose]
                )

            with gr.Tab("åº”ç”¨ç¨‹åºç¼–ç¨‹æ¥å£") as api_tweak:
                with gr.Row():
                    with gr.Column(scale=3):
                        code = gr.Code(
                            value=api_guid, 
                            language="python", 
                            interactive=False, 
                            label="LangServe æä¾›æœåŠ¡ï¼ˆ åŸºäº FastAPI ï¼‰"
                        )
                    with gr.Column(scale=1):
                        system_command = gr.Textbox(
                            lines= 3, 
                            label="ç³»ç»ŸæŒ‡ä»¤",  
                            placeholder="ç”¨äºæ›´æ”¹ AI è¡Œä¸ºï¼šå¦‚äººç‰©è®¾å®šã€è¯­è¨€é£æ ¼ã€ä»»åŠ¡æ¨¡å¼ç­‰...", 
                            interactive = True
                        )
                        chat_mode_choose_1 = gr.Radio(
                            choices=chatmode, 
                            label="å¯¹è¯æ¨¡å¼", 
                            value=chatmode[0], 
                            interactive=True
                        )
                        history_analyze_1 = gr.Radio(
                            choices=["å¼€å¯","å…³é—­"], 
                            label="å†å²åˆ†æ", 
                            value="å…³é—­", 
                            interactive=True
                        )
                        query_enhance_2 = gr.Radio(
                            choices=["å¼€å¯","å…³é—­"], 
                            label="è¯¢é—®é€»è¾‘ä¼˜åŒ–", 
                            value="å…³é—­", 
                            interactive=True, 
                        )
                        query_enhance_2_1 = gr.Radio(
                            choices=["å¼€å¯","å…³é—­"], 
                            label="è¯¢é—®å…³é”®è¯ä¼˜åŒ–", 
                            value="å…³é—­", 
                            interactive=True
                        )
                        db_test_1 = gr.Radio(
                            choices=["å¼€å¯","å…³é—­"], 
                            label="æ•°æ®åº“æµ‹è¯•", 
                            value="å…³é—­", 
                            interactive=True
                        )
                        with gr.Accordion(label="è¿›é˜¶é…ç½®", open=False):
                            history_len = gr.Slider(minimum=1, maximum=10, value=3, step=1, label="å†å²å¯¹è¯é‡", interactive=True)
                            history_time = gr.Slider(minimum=30, maximum=21600, value=7200, step=1, label="å†å²å¯¹è¯æœ‰æ•ˆæ—¶é•¿ï¼ˆ ç§’ ï¼‰", interactive=True)
                            max_tokens = gr.Slider(minimum=200, maximum=2048, value=800, step=1, label="Max Tokens", interactive=True)
                            temperature = gr.Slider(minimum=0, maximum=1, value=0, step=0.1, label="Temperature", interactive=True)
                            reteriver_k = gr.Slider(minimum=1, maximum=30, value=20, step=1, label="é¢„å–å›æ–‡æœ¬é‡", interactive=True)
                            reteriver_k_final = gr.Slider(minimum=1, maximum=30, value=5, step=1, label="æœ€å¤§å–å›æ–‡æœ¬é‡", interactive=True)
                            reteriver_k_relate = gr.Slider(minimum=1, maximum=30, value=10, step=1, label="æœ€å¤§è¿½é—®æ–‡æœ¬é‡", interactive=True)
                            score_threshold = gr.Slider(minimum=0, maximum=1, value=0.3, step=0.1, label="ç›¸ä¼¼é˜ˆå€¼", interactive=True)
                        api_refresh = gr.Button(value="åˆ·æ–°é…ç½®")
                        api_save = gr.Button(value="ä¿å­˜é…ç½®")
                        api_reset = gr.Button(value="é‡åˆ¶é…ç½®")


                api_tweak.select(
                    fn=load_from_api_1,
                    inputs=[],
                    outputs=[system_command, chat_mode_choose_1, history_analyze_1, query_enhance_2, query_enhance_2_1, db_test_1, history_len, history_time, max_tokens, temperature, reteriver_k, reteriver_k_final, reteriver_k_relate, score_threshold]
                )
                
                query_enhance_2.input(
                    fn=chatgpt_info, 
                    inputs=[], 
                    outputs=[]
                )
                
                query_enhance_2_1.input(
                    fn=chatgpt_info, 
                    inputs=[], 
                    outputs=[]
                )
                
                api_refresh.click(
                    fn=load_from_api_1,
                    inputs=[],
                    outputs=[system_command, chat_mode_choose_1, history_analyze_1, query_enhance_2, query_enhance_2_1, db_test_1, history_len, history_time, max_tokens, temperature, reteriver_k, reteriver_k_final, reteriver_k_relate, score_threshold]
                )
                
                api_save.click(
                    fn=save_setting_1, 
                    inputs=[system_command, chat_mode_choose_1, history_analyze_1, query_enhance_2, query_enhance_2_1, db_test_1, history_len, history_time, max_tokens, temperature, reteriver_k, reteriver_k_final, reteriver_k_relate, score_threshold], 
                    outputs=[]
                )
                
                api_reset.click(
                    fn=reset_setting, 
                    inputs=[], 
                    outputs=[system_command, chat_mode_choose_1, history_analyze_1, query_enhance_2, query_enhance_2_1, db_test_1, history_len, history_time, max_tokens, temperature, reteriver_k, reteriver_k_final, reteriver_k_relate, score_threshold]
                )

    tweaks.queue(default_concurrency_limit=concurrency_limit)  # WebUI å†…æœ€å¤§å¹¶å‘å¤„ç†é‡
    tweaks.launch(allowed_paths=[f"/{project_name_1}/packages/sources"], show_api=False, favicon_path=f"{sign_path}", server_name="0.0.0.0", server_port=6006)
    # tweaks.queue(api_open=False).launch(allowed_paths=[f"/{project_name_1}/packages/sources"], show_api=False, favicon_path=f"{sign_path}", server_name="0.0.0.0", server_port=6006)


